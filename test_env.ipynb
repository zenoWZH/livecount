{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading weights state\n"
     ]
    }
   ],
   "source": [
    "print ('loading weights state')\n",
    "f = open('weights.save', 'rb')\n",
    "loaded_objects = []\n",
    "for i in range(5):\n",
    "    loaded_objects.append(pickle.load(f,encoding='bytes'))\n",
    "f.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "nppara = np.array(loaded_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nppara.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 20, 5, 5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nppara[0,0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "#import theano.tensor as T\n",
    "#from theano.tensor.signal import downsample\n",
    "#from theano.tensor.nnet import conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "class LogisticRegression(object):\n",
    "\n",
    "    def __init__(self, inputs, n_in, n_out):\n",
    "\n",
    "        # initialize with 0 the weights W as a matrix of shape (n_in, n_out)\n",
    "        self.W = tf.variable(np.zeros((n_in, n_out),dtype='float32'),name='W')\n",
    "        # initialize the baises b as a vector of n_out 0s\n",
    "        self.b = tf.variable(np.zeros((n_out),dtype='float32'),name='b')\n",
    "\n",
    "        # compute vector of class-membership probabilities in symbolic form\n",
    "        self.p_y_given_x = tf.nn.softmax(tf.dot(inputs, self.W) + self.b)\n",
    "\n",
    "        self.p_y_given_x_printed = tf.Print(data = self.p_y_given_x, message = 'p_y_given_x = ')\n",
    "        #self.p_y_given_x_printed = self.p_y_given_x\n",
    "\n",
    "        # compute prediction as class whose probability is maximal in\n",
    "        # symbolic form\n",
    "        self.y_pred = tf.arg_max(self.p_y_given_x, axis=1)  \n",
    "       # parameters of the model\n",
    "        self.params = [self.W, self.b]\n",
    "\n",
    "    def __getstate__(self):\n",
    "        return (self.W.get_variable(), self.b.get_variable())\n",
    "    \n",
    "    def __setstate__(self, state):\n",
    "        W, b = state\n",
    "        self.W.assign(W)\n",
    "        self.b.sassign(b)\n",
    "\n",
    "    def negative_log_likelihood(self, y):\n",
    "        return -tf.mean(tf.log(self.p_y_given_x)[tf.arange(y.shape[0]), y])\n",
    "\n",
    "    def errors(self, y):\n",
    "        # check if y has same dimension of y_pred\n",
    "        if y.ndim != self.y_pred.ndim:\n",
    "            raise TypeError('y should have the same shape as self.y_pred',\n",
    "                ('y', targetf.type, 'y_pred', self.y_pred.type))\n",
    "        # check if y is of the correct datatype\n",
    "        if y.dtype.startswith('int'):\n",
    "            # the tf.neq operator returns a vector of 0s and 1s, where 1\n",
    "            # represents a mistake in prediction\n",
    "            return tf.mean(tf.neq(self.y_pred, y))\n",
    "        else:\n",
    "            raise NotImplementedError()\n",
    "\n",
    "    def get_output_labels(self, y):\n",
    "        return (((self.y_pred-y)*0 + self.y_pred), self.p_y_given_x)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class HiddenLayer(object):\n",
    "    def __init__(self, rng, inputs, n_in, n_out, W=None, b=None,\n",
    "                 activation=tf.tanh):\n",
    "        self.inputs = inputs\n",
    "\n",
    "        if W is None:\n",
    "            W_values = np.asarray(rng.uniform(\n",
    "                    low=-np.sqrt(6. / (n_in + n_out)),\n",
    "                    high=np.sqrt(6. / (n_in + n_out)),\n",
    "                    size=(n_in, n_out)), dtype='float32')\n",
    "            if activation == tf.sigmoid:\n",
    "                W_values *= 4\n",
    "\n",
    "            W = tf.Variable(value=W_values, name='W')\n",
    "            self.W = W\n",
    "            \n",
    "        else:\n",
    "            W = tf.Variable(value=W, name='W')\n",
    "\n",
    "        if b is None:\n",
    "            b_values = np.zeros((n_out,), dtype='float32')\n",
    "            b = tf.Variable(value=b_values, name='b')\n",
    "            self.b = b\n",
    "            \n",
    "        else:\n",
    "            b = tf.Variable(value=b, name='b')\n",
    "            self.b = b\n",
    "        \n",
    "        \n",
    "\n",
    "        lin_output = tf.dot(inputs, self.W) + self.b\n",
    "        self.output = (lin_output if activation is None\n",
    "                       else activation(lin_output))                       \n",
    "                       #else tf.maximum(0.0, lin_output)) #activation(lin_output))                       \n",
    "        # parameters of the model\n",
    "        self.params = [self.W, self.b]\n",
    "\n",
    "    def __getstate__(self):\n",
    "        return (self.W.get_variable(), self.b.get_variable())\n",
    "    \n",
    "    def __setstate__(self, state):\n",
    "        W, b = state\n",
    "        self.W.set_value(W)\n",
    "        self.b.set_value(b)\n",
    "\n",
    "    def get_output_vector(self):\n",
    "        return (self.output)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class LeNetConvPoolLayer(object):\n",
    "\n",
    "    def __init__(self, rng, inputs, filter_shape, image_shape, W=None, b=None, poolsize=(2, 2)):\n",
    "        #data_format= \"NCHW\"\n",
    "        assert image_shape[1] == filter_shape[1]\n",
    "        self.inputs = tf.transponse(inputs, parm=[0,2,3,1])\n",
    "\n",
    "        # there are \"num inputs feature maps * filter height * filter width\"\n",
    "        # inputss to each hidden unit\n",
    "        fan_in = np.prod(filter_shape[1:])\n",
    "        # each unit in the lower layer receives a gradient from:\n",
    "        # \"num output feature maps * filter height * filter width\" /\n",
    "        #   pooling size\n",
    "        fan_out = (filter_shape[0] * np.prod(filter_shape[2:]) /\n",
    "                   np.prod(poolsize))\n",
    "        # initialize weights with random weights\n",
    "        if W is None:\n",
    "            W_bound = np.sqrt(6. / (fan_in + fan_out))\n",
    "            self.W = tf.transponse(tf.Variable(np.asarray(rng.uniform(low=-W_bound, high=W_bound, size=filter_shape),dtype='float32')), perm=[2,3,1,0])\n",
    "        else:\n",
    "            self.W = tf.transponse(tf.Variable(value=W),perm=[2,3,1,0])\n",
    "        # the bias is a 1D tensor -- one bias per output feature map\n",
    "        if b is None:\n",
    "            b_values = np.zeros((filter_shape[0],), dtype='float32')\n",
    "            self.b = tf.Variable(value=b_values)\n",
    "        else:\n",
    "            self.b = tf.Variable(value=b)\n",
    "\n",
    "        # convolve inputs feature maps with filters   ********\n",
    "        conv_out = tf.add(tf.nn.conv2d(inputs, self.W, strides=(1,1,1,1), padding=\"VALID\"),self.b)\n",
    "\n",
    "        # downsample each feature map individually, using maxpooling   *******\n",
    "        pooled_out = tf.nn.max_pool(conv_out, ksize=[1,2,2,1], strides=[1,2,2,1], padding='VALID')\n",
    "\n",
    "        self.output = tf.maximum(0.0, pooled_out + self.b.dimshuffle('x', 0, 'x', 'x'))\n",
    "                \n",
    "        # store parameters of this layer\n",
    "        self.params = [self.W, self.b]\n",
    "\n",
    "    def __getstate__(self):\n",
    "        return (self.W.get_variable(), self.b.get_variable())\n",
    "    \n",
    "    def __setstate__(self, state):\n",
    "        W, b = state\n",
    "        self.W.set_value(W)\n",
    "        self.b.set_value(b)        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
